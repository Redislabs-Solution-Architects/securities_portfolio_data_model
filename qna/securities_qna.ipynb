{
  "cells": [
    {
      "cell_type": "code",
      "id": "HqRohfRRZgFWtj1zYJIyvR5n",
      "metadata": {
        "tags": [],
        "id": "HqRohfRRZgFWtj1zYJIyvR5n"
      },
      "source": [
        "!pwd\n",
        "!pip install --upgrade pip\n",
        "\n",
        "# Install required libraries\n",
        "!python3 -m pip -q install redis\n",
        "!pip install -U langchain gradio\n",
        "!pip install -U langchain-core\n",
        "!pip install -U langchain-google-vertexai\n",
        "!pip install -U langchain-community\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Update the 'host' field with the correct Redis host URL\n",
        "host = ''\n",
        "port = 15337\n",
        "password = 'admin'\n"
      ],
      "metadata": {
        "id": "sjUooyI9VlAu"
      },
      "id": "sjUooyI9VlAu",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import redis\n",
        "\n",
        "client = redis.Redis(host = host, port=port, decode_responses=True, password=password)\n",
        "\n",
        "print(client.ping())\n",
        "\n",
        "REDIS_URL = f\"redis://:{password}@{host}:{port}\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UnZUjIFVxWA",
        "outputId": "03c4e427-923d-41af-f9e4-39b5407b1474"
      },
      "id": "4UnZUjIFVxWA",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from redis.commands.search.field import NumericField, TextField, TagField, VectorField\n",
        "from redis.commands.search.indexDefinition import IndexDefinition, IndexType\n",
        "from redis.commands.search.query import NumericFilter, Query\n",
        "import redis.commands.search.aggregation as aggregations\n",
        "import redis.commands.search.reducers as reducers\n",
        "\n",
        "\n",
        "INDEX_NAME = f\"idx_scan_docs\"\n",
        "\n",
        "schema = (TextField(\"$.accountNo\", as_name=\"accountNo\"),\n",
        "          NumericField(\"$.date\", as_name=\"date\", sortable=True),\n",
        "          TextField(\"$.desc\", as_name=\"desc\"),\n",
        "          VectorField(\"$.desc_vector\", \"HNSW\",\n",
        "              {\n",
        "              \"TYPE\": \"FLOAT32\",\n",
        "              \"DISTANCE_METRIC\": \"COSINE\",\n",
        "              #\"as_name\": \"desc_vector\",\n",
        "              \"DIM\": 768,\n",
        "              }))\n",
        "\n",
        "client.ft(INDEX_NAME).create_index(schema,\n",
        "      definition=IndexDefinition(prefix=[\"trading:securitylot:\"], index_type=IndexType.JSON))\n"
      ],
      "metadata": {
        "id": "c_ApoWSsDyuA"
      },
      "id": "c_ApoWSsDyuA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_vertexai import VertexAIEmbeddings\n",
        "from google.colab import auth\n",
        "from getpass import getpass\n",
        "\n",
        "from typing import Generator, List, Any\n",
        "import numpy as np\n",
        "\n",
        "import vertexai\n",
        "\n",
        "auth.authenticate_user()\n",
        "print('Authenticated')\n",
        "\n",
        "# input your GCP project ID and region for Vertex AI\n",
        "PROJECT_ID = getpass(\"PROJECT_ID:\")\n",
        "REGION = input(\"REGION:\")\n",
        "\n",
        "print(f'PROJECT_ID: {PROJECT_ID} & REGION: {REGION}')\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=REGION)\n",
        "\n",
        "def embed_text(text=[]):\n",
        "   embeddings = VertexAIEmbeddings(model_name=\"text-embedding-004\")\n",
        "   return embeddings.embed_documents(text)\n",
        "\n",
        "def convert_embedding(emb: List[float]):\n",
        "   return np.array(emb).astype(np.float32).tobytes()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtDISaRFRkee",
        "outputId": "cbfe33f2-e0f6-4eaa-97b4-93a82eae5c4e"
      },
      "id": "FtDISaRFRkee",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authenticated\n",
            "PROJECT_ID: central-beach-194106 & REGION: us-central1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import json\n",
        "import time\n",
        "from redis.commands.search.query import Query\n",
        "\n",
        "\n",
        "qry = '@embeddings:{false}'\n",
        "limit = 1000\n",
        "query = (Query(qry).paging(0, limit).sort_by(\"date\"))\n",
        "docs = client.ft(\"idx_trading_security_lot\").search(query).docs\n",
        "\n",
        "doc_array = []\n",
        "desc_vector_list = []\n",
        "count = 0\n",
        "while len(docs) > 0:\n",
        "    for doc in docs:\n",
        "        temp = json.loads(doc.json)\n",
        "        temp['id'] = doc.id\n",
        "        doc_array.append(temp)\n",
        "        count += 1\n",
        "\n",
        "        if len(doc_array) == 1000:\n",
        "            vectors = embed_text([d['desc']for d in doc_array])\n",
        "\n",
        "            desc_vector_list.extend(vectors)\n",
        "            print(desc_vector_list)\n",
        "            pipeline = client.pipeline()\n",
        "            for index, vec in enumerate(desc_vector_list):\n",
        "                d = doc_array[index]\n",
        "                d['desc_vector'] = vec\n",
        "                d['embeddings'] = True\n",
        "                if index < 4:\n",
        "                  print(d)\n",
        "                pipeline.json().set(d['id'], \"$\", d)\n",
        "            pipeline.execute()\n",
        "\n",
        "            desc_vector_list = []\n",
        "            doc_array = []\n",
        "            time.sleep(5)\n",
        "\n",
        "    if len(doc_array) > 0:\n",
        "        print(f\"Inside second block {len(doc_array)}\")\n",
        "        vectors = embed_text([d['desc']for d in doc_array])\n",
        "        desc_vector_list.extend(vectors)\n",
        "        pipeline = client.pipeline()\n",
        "        index = 0\n",
        "        for index, vec in enumerate(desc_vector_list):\n",
        "            d = doc_array[index]\n",
        "            d['desc_vector'] = vec\n",
        "            d['embeddings'] = True\n",
        "            pipeline.json().set(d['id'], \"$\", d)\n",
        "        pipeline.execute()\n",
        "        print(f\"total rec --> {index}\")\n",
        "        desc_vector_list = []\n",
        "        doc_array = []\n",
        "        time.sleep(5)\n",
        "\n",
        "    query = (Query(qry).paging(0, limit).sort_by(\"date\"))\n",
        "    docs = client.ft(\"idx_trading_security_lot\").search(query).docs\n",
        "\n",
        "print(f\"Total record count: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2y0bdiEVvdG",
        "outputId": "3af53e99-e1b1-45b2-8e32-e761555135a2"
      },
      "id": "j2y0bdiEVvdG",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total record count: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import re\n",
        "from redis.commands.search.query import Query\n",
        "\n",
        "def get_accNo(query):\n",
        "  accNo = None\n",
        "  pattern = r'ACC\\d+'\n",
        "  match = re.search(pattern, query)\n",
        "  if match:\n",
        "      accNo = match.group()\n",
        "\n",
        "  return accNo\n",
        "\n",
        "def get_contexts(accNo):\n",
        "  query = (\n",
        "      Query(f'(@accountNo:{accNo})')\n",
        "      .paging(0, 200)\n",
        "      .return_fields('desc')\n",
        "      .dialect(2)\n",
        "  )\n",
        "\n",
        "  result_docs = client.ft(INDEX_NAME).search(query).docs\n",
        "\n",
        "  desc_collection = []\n",
        "  for d in result_docs:\n",
        "    desc_collection.append(d.desc)\n",
        "\n",
        "  contexts = \"-\" + \"\\n-\".join([str for str in desc_collection])\n",
        "  print(contexts)\n",
        "  return contexts\n",
        ""
      ],
      "metadata": {
        "id": "feOuI6LwSlVf"
      },
      "id": "feOuI6LwSlVf",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Invoke Google Vertex LLM using Langchain\n",
        "from langchain_google_vertexai import VertexAI\n",
        "\n",
        "\n",
        "def create_prompt(prompt_template: str, **kwargs) -> str:\n",
        "  return prompt_template.format(**kwargs)\n",
        "\n",
        "PROMPT = \"\"\"You are a helpful virtual financial & investment assistant. Use the provided context to answer the questions related to stocks that gets credited to the account number. Don't blindly make things up.\n",
        "\n",
        "    Context:\n",
        "    {context}\n",
        "\n",
        "    QUESTION:\n",
        "    {query}?\n",
        "\n",
        "    ANSWER:\"\"\"\n",
        "\n",
        "\n",
        "def get_response(query):\n",
        "    accNo = get_accNo(query)\n",
        "    if accNo is None:\n",
        "      return \"Please provide a valid account number (e.g ACC10000) to fetch the details\"\n",
        "\n",
        "    contexts = get_contexts(accNo)\n",
        "\n",
        "    query1 = \"How many stocks has been credited to account ACC10000 between 1st Nov, 2023 and 30th Nov, 2023?\"\n",
        "    query2 = \"What was the total portfolio value of ABCBANK stock till Aug 31st, 2023 for account ACC10000?\"\n",
        "    query3 = \"Suppose portfolio against account ACC10000 had 0 financial value on July 13th, 2023 and user has not sold any stocks so far. Which stock has the most financial value?\"\n",
        "    query4 = \"How many stocks has been credited to accountNo (account number) ACC10000?\"\n",
        "    query5 = \"Which is the most profitable stock in terms of total financial value for ACC10000?\"\n",
        "\n",
        "    full_prompt = create_prompt(\n",
        "            prompt_template=PROMPT,\n",
        "            context=contexts,\n",
        "            query=query\n",
        "          )\n",
        "\n",
        "    llm = VertexAI(\n",
        "        model_name=\"gemini-1.5-pro-002\",\n",
        "        max_output_tokens=2048,\n",
        "        temperature=0.5,\n",
        "        verbose=True,\n",
        "    )\n",
        "    return llm.invoke(full_prompt)\n"
      ],
      "metadata": {
        "id": "DYtdUxxFSxh9"
      },
      "id": "DYtdUxxFSxh9",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def handle(query):\n",
        "    response = get_response(query)\n",
        "    return response\n",
        "\n",
        "iface = gr.Interface(fn=handle, inputs=\"text\", outputs=\"text\")\n",
        "iface.launch(share=True)"
      ],
      "metadata": {
        "id": "UmsYlwP9XZ2G"
      },
      "id": "UmsYlwP9XZ2G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iface.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvmnrq_3YY6p",
        "outputId": "0be316c9-9fb6-45b9-b2ac-717c93505c20"
      },
      "id": "nvmnrq_3YY6p",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing server running on port: 7860\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}